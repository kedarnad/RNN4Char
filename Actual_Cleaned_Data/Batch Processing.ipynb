{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, itertools\n",
    "from gensim.models import Word2Vec\n",
    "import nltk, os\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the original dataset:\n",
    "\n",
    "file_data = open('gh_create_all_fields_cleaned_data.txt', 'rt')\n",
    "# reading the sentences:\n",
    "sentences=file_data.read()\n",
    "sentences=sentences.split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing randomly selected 50 sentenes from the OG dataset:\n",
    "import random\n",
    "train_sent=[]\n",
    "\n",
    "for i in range(11):\n",
    "    num = random.randrange(0, len(sentences))\n",
    "    train_sent.append(sentences[num])\n",
    "    \n",
    "# train_sent.append(\"$& $$& i love $pence is $$&\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " out, inp = [\" \".join(x.split()[1:]) for x in train_sent], [\" \".join(x.split()[:1]) for x in train_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_map=dict()\n",
    "out_map=dict()\n",
    "for index, val in enumerate(out):\n",
    "    table_map[inp[index]]=out[index]\n",
    "    out_map[out[index]]=inp[index]\n",
    "train_sent=[]\n",
    "for key in table_map:\n",
    "    sent=\"$\"+key+\"&\"+\" \"+table_map[key]\n",
    "    train_sent.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the essential visualization parameters:\n",
    "from d2l import tensorflow as d2l\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)\n",
    "\n",
    "train_random_iter, vocab_random_iter = d2l.load_data_time_machine(\n",
    "    batch_size, num_steps, use_random_iter=True)\n",
    "\n",
    "\n",
    "\n",
    "char_data =\"\"\n",
    "\n",
    "for sent in train_sent:\n",
    "    char_data+=sent+\"\\n\"\n",
    "\n",
    "chars= list(set(char_data))\n",
    "\n",
    "#create dictionary mapping for each char\n",
    "char_to_ix = {ch:i for (i,ch) in enumerate(chars)}\n",
    "ix_to_char = {i:ch for (i,ch) in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params2(vocab_size, num_hidden):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return tf.random.normal(shape=shape,stddev=0.01,mean=0,dtype=tf.float32)\n",
    "\n",
    "    # Hidden layer parameters\n",
    "    E = tf.Variable(normal((vocab_size, 10)), dtype=tf.float32)\n",
    "    W_xh = tf.Variable(normal((num_inputs, num_hiddens)), dtype=tf.float32)\n",
    "    W_hh = tf.Variable(normal((num_hiddens, num_hiddens)), dtype=tf.float32)\n",
    "    b_h = tf.Variable(tf.zeros(num_hiddens), dtype=tf.float32)\n",
    "    # Output layer parameters\n",
    "    W_hq = tf.Variable(normal((num_hiddens, num_outputs)), dtype=tf.float32)\n",
    "    b_q = tf.Variable(tf.zeros(num_outputs), dtype=tf.float32)\n",
    "    M = tf.Variable(tf.random.uniform([W_xh.shape[1], vocab_size], dtype=tf.float32))\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q, E, M]\n",
    "#     params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for converting numpy vectors into tensorflow vectors:\n",
    "def my_func(arg):\n",
    "    arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "    print(arg)\n",
    "    return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state2(batch_size, num_hiddens):\n",
    "    return (tf.zeros((batch_size, num_hiddens)), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn2(inputs, state, params, curr_sent, vocab_size, word2vec_model):\n",
    "    # Here `inputs` shape: (`num_steps`, `batch_size`, `vocab_size`)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q,E, M = params\n",
    "    \n",
    "    # calculating the values from the encoder function\n",
    "    result=tf.zeros([vocab_size, 1], tf.float32)\n",
    "    for every_char in curr_sent:\n",
    "        tfcharEmb = my_func(word2vec_model[every_char])\n",
    "        tfcharEmb=tf.reshape(tfcharEmb, [10, 1])\n",
    "        result+= tf.matmul(E, tfcharEmb)\n",
    "        \n",
    "#     M=tf.random.uniform([W_xh.shape[1], vocab_size], dtype=tf.float32)\n",
    "    H, = state\n",
    "    outputs = []\n",
    "\n",
    "\n",
    "    for X in inputs:\n",
    "        X = tf.reshape(X,[-1,W_xh.shape[0]])\n",
    "        a= tf.matmul(X, W_xh)\n",
    "        b= tf.matmul(H, W_hh)\n",
    "        c = tf.matmul(M, result)\n",
    "        c =  tf.reshape(c, [c.shape[1], c.shape[0]])\n",
    "        H = tf.nn.sigmoid(a + b + c + b_h, name='sigmoid')\n",
    "        Y = tf.matmul(H, W_hq) + b_q\n",
    "        y_out = tf.nn.softmax(Y)\n",
    "        outputs.append(y_out)\n",
    "    return tf.concat(outputs, axis=0), (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelScratch2: #@save\n",
    "    \"\"\"A RNN Model implemented from scratch.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens,\n",
    "                 init_state, forward_fn, word2vec):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "        self.word2vec=word2vec\n",
    "\n",
    "    def __call__(self, X, state, params, curr_sent):\n",
    "        print(X, X.shape)\n",
    "#         X = tf.one_hot(tf.transpose(X), self.vocab_size)\n",
    "#         X = tf.cast(X, tf.float32)\n",
    "        return self.forward_fn(X, state, params, curr_sent, self.vocab_size, self.word2vec)\n",
    "\n",
    "    def begin_state(self, batch_size):\n",
    "        return self.init_state (batch_size, self.num_hiddens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, params, table_map, char_to_ix, ix_to_char, inp, vocab_size):\n",
    "    \"traing the modified model\"\n",
    "    state=None\n",
    "    \n",
    "    threshold = 0.05\n",
    "    lr=1\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    updater = tf.keras.optimizers.SGD(lr)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_res=[] # storage for the resultant loss\n",
    "    loss_epochs = [] #keeping of the loss per epoch\n",
    "    epochs = 1200\n",
    "    metric = d2l.Accumulator(2)\n",
    "    timer=d2l.Timer()\n",
    "    \n",
    "    \n",
    "    while epochs>0:\n",
    "        \n",
    "        loss_per_epoch=0\n",
    "        \n",
    "        for batch in range(0, len(inp), 2):\n",
    "            currBatch_X=[]\n",
    "            currBatch_y=[]\n",
    "\n",
    "            maxLen = len(max(inp[batch:batch+2], key=len))\n",
    "            maxLen+=2\n",
    "            \n",
    "            \n",
    "            for every_table in inp[batch:batch+2]:\n",
    "\n",
    "                #padding the current word\n",
    "                target_word = \"$\"+every_table+\"&\"\n",
    "    #             print(\"target word -> \",target_word)\n",
    "\n",
    "                input_str = target_word[0:len(target_word)-1]\n",
    "                target_str = target_word[1:len(target_word)]\n",
    "\n",
    "                inputs = [char_to_ix[ch] for ch in input_str]\n",
    "                targets = [char_to_ix[ch] for ch in target_str]\n",
    "                print(inputs)\n",
    "                X = tf.reshape(inputs, (1, len(inputs)))\n",
    "                Y_out = tf.reshape(targets, (1, len(targets)))\n",
    "                \n",
    "                X = tf.one_hot(tf.transpose(X), vocab_size)\n",
    "              \n",
    "                \n",
    "                for _ in range(maxLen-len(target_word)):\n",
    "                    temp = [0] * vocab_size\n",
    "#                     temp = my_func(temp)\n",
    "                    temp = tf.Variable(tf.reshape(temp, [-1, len(temp)]))\n",
    "                    temp = tf.reshape(temp, (1, temp.shape[0], temp.shape[1]))\n",
    "                    temp =tf.cast(temp, tf.float32)\n",
    "                    X = tf.concat([X, temp],0)\n",
    "                \n",
    "                \n",
    "                print(\" X-> \", X)\n",
    "                X = tf.cast(X, tf.float32)\n",
    "                \n",
    "                print(X.shape)\n",
    "                \n",
    "                \n",
    "                Y_true=tf.one_hot(Y_out, len(char_to_ix),on_value=1.0, off_value=0.0,axis=-1)\n",
    "                Y_true=Y_true[0];\n",
    "\n",
    "\n",
    "                # The actual crux of training the data:\n",
    "\n",
    "    #             if state is None:\n",
    "\n",
    "    #                 state = model.begin_state(batch_size=X.shape[0])\n",
    "\n",
    "    #             with tf.GradientTape(persistent=True) as g:\n",
    "    # #                 print('I am here 1')\n",
    "    #                 g.watch(params)\n",
    "    #                 y_hat, state= model(X, state, params, table_map[every_table])\n",
    "    #                 y = tf.reshape(Y_out, (-1))\n",
    "    #                 axis_0 = np.shape(y_hat.numpy())[0]\n",
    "    #                 axis_1 = np.shape(y_hat.numpy())[1]\n",
    "    #                 Y_true=tf.reshape(Y_true, [axis_0, axis_1])\n",
    "    #                 # calculating the loss\n",
    "    #                 l = loss(Y_true, y_hat)\n",
    "\n",
    "    # #             print(l)\n",
    "\n",
    "    # #             print('I am here 2')\n",
    "    #             grads = g.gradient(l, params)\n",
    "    #             grads = grad_clipping(grads, 1)\n",
    "    #             optimizer.apply_gradients(zip(grads, params))\n",
    "    # #             updater.apply_gradients(zip(grads, params))\n",
    "    # #             print('I am here 3')\n",
    "    # #             metric.add(l * tf.size(y).numpy(), tf.size(y).numpy())\n",
    "    #             loss_per_epoch=l\n",
    "\n",
    "    #         # after every epoch\n",
    "    #         loss_epochs.append(loss_per_epoch)\n",
    "    # #         loss_res.append(math.exp(metric[0] / metric[1]))\n",
    "        epochs=epochs-1\n",
    "        break\n",
    "    return loss_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(grads, theta): #@save\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    theta = tf.constant(theta, dtype=tf.float32)\n",
    "    norm = tf.math.sqrt(sum((tf.reduce_sum(grad ** 2)).numpy()\n",
    "                        for grad in grads))\n",
    "    norm = tf.cast(norm, tf.float32)\n",
    "    new_grad = []\n",
    "    if tf.greater(norm, theta):\n",
    "        for grad in grads:\n",
    "            new_grad.append(grad * theta / norm)\n",
    "    else:\n",
    "        for grad in grads:\n",
    "            new_grad.append(grad)\n",
    "    return new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to calculate word tokenizations and tokenizers:\n",
    "# which would be later used for calculating the word to \n",
    "\n",
    "def filter_words(sentence):\n",
    "    ll = [[nltk.word_tokenize(w), ' '] for w in sentence.split()]\n",
    "#     print(list(itertools.chain(*list(itertools.chain(*ll)))))\n",
    "#     return [word.lower() if word.isalpha() else \" \" for word in [nltk.word_tokenize(sentence), \" \"]]\n",
    "    return list(itertools.chain(*list(itertools.chain(*ll))))\n",
    "\n",
    "def tokenize(text):\n",
    "    return [filter_words(sentence) for sentence in nltk.sent_tokenize(text)]\n",
    "\n",
    "tokenized_words=[]\n",
    "sent_data=[]\n",
    "for sentence in out:\n",
    "    sent_mod=''\n",
    "    for char in sentence:\n",
    "        sent_mod+=char+' ' \n",
    "#     print(sent_mod)\n",
    "#     print(nltk.sent_tokenize(sent_mod))\n",
    "    tokenized_words.extend(tokenize(sent_mod))\n",
    "    sent_data.append(sentence)\n",
    "\n",
    "word2vec_model = Word2Vec(tokenized_words, \n",
    "                          sg=1,  # here we will use skipgram 0 is for CBROW; skip gram is for smaller models \n",
    "                          size=10,\n",
    "                          min_count=1 # word needs to occur atleast once\n",
    "                         )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 1, 7, 15, 19, 12, 14, 0, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(9, 1, 29), dtype=float32)\n",
      "(9, 1, 29)\n",
      "[16, 21, 7, 25, 17, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(9, 1, 29), dtype=float32)\n",
      "(9, 1, 29)\n",
      "[16, 20, 15, 2, 25, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(7, 1, 29), dtype=float32)\n",
      "(7, 1, 29)\n",
      "[16, 7, 25, 17, 2, 25, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(7, 1, 29), dtype=float32)\n",
      "(7, 1, 29)\n",
      "[16, 19, 15, 2, 25, 18, 12, 4, 2]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(9, 1, 29), dtype=float32)\n",
      "(9, 1, 29)\n",
      "[16, 20, 15, 2, 25, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(9, 1, 29), dtype=float32)\n",
      "(9, 1, 29)\n",
      "[16, 7, 20, 19, 5, 7, 8]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(7, 1, 29), dtype=float32)\n",
      "(7, 1, 29)\n",
      "[16, 4, 28, 12, 11, 17]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(7, 1, 29), dtype=float32)\n",
      "(7, 1, 29)\n",
      "[16, 13, 4, 4, 7, 20, 14, 19, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(9, 1, 29), dtype=float32)\n",
      "(9, 1, 29)\n",
      "[16, 4, 28, 13, 14, 14, 2, 11, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(9, 1, 29), dtype=float32)\n",
      "(9, 1, 29)\n",
      "[16, 1, 25, 7, 17, 20, 4, 19, 15]\n",
      " X->  tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0.]]], shape=(9, 1, 29), dtype=float32)\n",
      "(9, 1, 29)\n"
     ]
    }
   ],
   "source": [
    "num_hiddens = 512        # declaration of number of hidden layers\n",
    "lr=0.1                   # declaration of regularization parameter\n",
    "seq_len=10               # this is a sequence length\n",
    "updater = tf.keras.optimizers.SGD(lr)\n",
    "# data_reader = DataReader(\"temp.txt\", seq_len)\n",
    "#defining the required params:\n",
    "params = get_params2(len(chars), num_hiddens)\n",
    "\n",
    "model=RNNModelScratch2(len(chars), num_hiddens, init_rnn_state2, rnn2, word2vec_model)\n",
    "loss_res =train(model, params, table_map, char_to_ix, ix_to_char, inp, len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = [0]*29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0] * 29\n",
    "#                     temp = my_func(temp)\n",
    "temp = tf.Variable(tf.reshape(temp, [-1, len(temp)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=tf.Variable(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 29), dtype=int32, numpy=\n",
       "array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]], dtype=int32)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(temp, (1,1,29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2 \n",
    "y=2\n",
    "for X, Y in train_iter:\n",
    "    x =X \n",
    "    y=Y\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 35), dtype=int32, numpy=\n",
       "array([[ 4, 15,  9, ..., 22,  2, 12],\n",
       "       [ 1, 21, 14, ...,  5,  6,  1],\n",
       "       [ 6,  1, 16, ..., 19,  4, 11],\n",
       "       ...,\n",
       "       [ 2, 10,  1, ...,  7, 10,  2],\n",
       "       [ 5,  6,  2, ...,  2, 24, 20],\n",
       "       [ 8, 13,  3, ...,  3,  1, 11]], dtype=int32)>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.one_hot(tf.transpose(x), len(vocab))\n",
    "X = tf.cast(X, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(35, 32, 28), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 35), dtype=int32, numpy=\n",
       "array([[15,  9,  5, ...,  2, 12, 12],\n",
       "       [21, 14, 21, ...,  6,  1,  7],\n",
       "       [ 1, 16,  7, ...,  4, 11, 13],\n",
       "       ...,\n",
       "       [10,  1,  9, ..., 10,  2,  1],\n",
       "       [ 6,  2,  1, ..., 24, 20, 12],\n",
       "       [13,  3,  9, ...,  1, 11,  7]], dtype=int32)>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
